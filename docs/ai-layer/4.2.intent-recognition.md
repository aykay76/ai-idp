# Intent Recognition & Parameter Extraction: Detailed Specification

## 1. Introduction

The Intent Recognition & Parameter Extraction component serves as the critical first step in our AI-powered IDP architecture. This component is responsible for transforming natural language requests from developers into structured data that the rest of the system can process. It bridges the gap between human expression and machine-understandable commands, ensuring that the system can reliably interpret and act upon developer requests.

## 2. Component Overview

This component performs three primary functions:

1. **Intent Recognition**: Identifying the type of infrastructure or service being requested
2. **Parameter Extraction**: Extracting specific values, configurations, and requirements from the natural language input
3. **Governance-Aware Guidance**: Leveraging organizational policies to guide conversations and validate parameters in real-time

Together, these functions convert unstructured developer requests into a structured intermediate representation that feeds into the MCP-based tool system.

## 3. Intent Recognition

### 3.1 Purpose

Intent recognition determines what the developer wants to create or modify. It classifies the request into known patterns that the system supports, such as "API server," "Kafka consumer," "database," etc.

### 3.2 Approach

We use a combination of techniques to ensure accurate intent recognition:

1. **LLM-based Classification**: A fine-tuned language model analyzes the conversation context and request to determine the most likely intent. 
 
2. **Pattern Matching**: For common, well-defined requests, we use pattern matching to quickly identify intents with high confidence.

3. **Contextual Analysis**: The system considers the conversation history to disambiguate requests that might have multiple interpretations.

4. **Confidence Scoring**: Each intent classification includes a confidence score, with low-confidence results triggering clarification questions.

### 3.3 Supported Intents

The system recognizes a predefined set of intents that map to available infrastructure patterns:

- `create_api_server`: Create a new API server
- `create_kafka_consumer`: Create a Kafka consumer application
- `create_kafka_producer`: Create a Kafka producer application
- `create_database`: Create a new database
- `create_cache`: Create a caching layer
- `create_storage`: Create storage resources
- `update_configuration`: Modify existing infrastructure
- `delete_resource`: Remove existing infrastructure

### 3.4 Implementation Details

The intent recognition process follows these steps:

1. **Conversation Preprocessing**: Clean and normalize the input text, removing irrelevant elements.

2. **Context Enrichment**: Add relevant context from the conversation history and user profile.

3. **Intent Classification**: Pass the enriched text to the classification model.

4. **Confidence Assessment**: Evaluate the model's confidence in its classification.

5. **Clarification (if needed)**: If confidence is below a threshold, ask clarifying questions.

6. **Intent Determination**: Finalize the intent based on classification and any clarifications.

### 3.5 Governance Integration

The intent recognition component incorporates governance policies at multiple points:

1. **Policy-Aware Prompting**: System prompts include relevant governance policies that guide the LLM's responses
2. **Real-time Validation**: Extracted parameters are validated against governance rules during the conversation
3. **Guided Refinement**: When potential policy violations are detected, the system guides users toward compliant alternatives
4. **Contextual Policy Retrieval**: Policies are dynamically retrieved based on user identity, team, and target environment

## 4. Parameter Extraction

### 4.1 Purpose

Parameter extraction identifies specific values, configurations, and requirements within the natural language request. While intent recognition tells us *what* the developer wants to create, parameter extraction tells us *how* they want it configured.

### 4.2 Approach

Parameter extraction uses a structured approach to identify and validate parameters:

1. **Schema-Guided Extraction**: Each intent has an associated parameter schema that defines what parameters can be extracted and their expected types.

6. **Entity Recognition**: The system identifies entities (names, numbers, technical terms) within the text.

7. **Relationship Mapping(*: The system maps extracted entities to specific parameters in the schema.

8. **Inference and Defaults**: For parameters not explicitly mentioned, the system infers values from context or applies sensible defaults.

9. **Validation**: Extracted parameters are validated against the schema and governance rules.

### 4.3 Parameter Types

The system handles various parameter types:

- **String Parameters**: Names, descriptions, identifiers
- **Numeric Parameters**: Sizes, quantities, limits
- **Boolean Parameters**: Flags, toggles
- **Enum Parameters**: Selections from predefined options
- **Complex Parameters**: Nested structures with multiple properties

### 4.4 Implementation Details

The parameter extraction process follows these steps:

1. **Schema Selection**: Based on the recognized intent, select the appropriate parameter schema.

2. **Entity Extraction**: Identify potential parameter values within the text.

3. **Entity Classification**: Classify each extracted entity according to the schema.

4. **Value Normalization**: Convert extracted values to the appropriate data types.

5. **Inference and Defaults**: Apply default values for missing parameters based on context and organizational standards.

6. **Validation**: Verify that all required parameters are present and that values are within acceptable ranges.

7. **Parameter Set Construction**: Assemble the final parameter set for processing.

## 5. Examples

### 5.1 Simple Example

**User Input**: "I need a new API server for user management called user-api"

**Processing**:
- **Intent Recognition**: `create_api_server` (confidence: 0.98)
- **Parameter Extraction**:
  - `name`: "user-api"
  - `purpose`: "user management"
  - `runtime`: (default: "nodejs")
  - `database`: (default: "postgres|-small")

**Output**:
```json
{
  "intent": "create_api_server",
  "confidence": 0.98,
  "parameters": {
    "name": "user-api",
    "purpose": "user management",
    "runtime": "nodejs",
    "database": "postgresq-small"
  }
}
```

##  5.2 Complex Example

**User Input**: "I need a Kafka consumer that processes orders from the `orders` topic. It should connect to our production Kafka cluster and use the Java runtime. Name it `order-processor`."

**Processing**:
- **Intent Recognition**: `create_kafka_consumer` (confidence: 0.96)
- **Parameter Extraction**:
  - `name`: "order-processor"
  - `topic`: "orders"
  - `cluster`: "production"
  - `runtime`: "java"
  - `consumer_group`: (inferred: "order-processor-group")
  - `auto_offset_reset`: (default: "latest")

**Output**:
```json
{
  "intent": "create_kafka_consumer",
  "confidence": 0.96,
  "parameters": {
    "name": "order-processor",
    "topic": "orders",
    "cluster": "production",
    "runtime": "java",
    "consumer_group": "order-processor-group",
    "auto_offset_reset": "latest"
  }
}
```

### 5.3 Example with Clarification

**User Input**: "I need a database"

**Processing**:
- **Intent Recognition**: `create_database` (confidence: 0.92)
- **Parameter Extraction**:
  - `name`: (missing - required)
  - `type`: (missing - required)
  - `size`: (missing - will use default)
  
**Clarification Question**: "I can help you create a database. What would you like to name it, and what type of database do you need? We support PostgreSQL, MySQL, and MongoDB."

**User Response**: "Call it product-catalog and use PostgreSQL"

**Updated Processing**:
- **Parameter Extraction**:
  - `name`: "product-catalog"
  - `type`: "postgresql"
  - `size`: (default: "small")

**Output**:
```json
{
  "intent": "create_database",
  "confidence": 0.92,
  "parameters": {
    "name": "product-catalog",
    "type": "postgresql",
    "size": "small"
  }
}
```

### 5.4 Governance-Aware Example

**User Input**: "I need a 500GB MongoDB database for production"

**Processing**:
- **Intent Recognition**: `create_database` (confidence: 0.95)
- **Parameter Extraction**:
  - `size`: "500GB"
  - `type`: "mongodb"
  - `environment`: "production"
- **Governance Check**: Size exceeds 100GB limit for production databases without approval

**System Response**: "I can help you create a MongoDB database for production. However, I should note that databases larger than 100GB require infrastructure team approval. Would you like to:
1. Request a 100GB database (no approval needed)
2. Proceed with the 500GB request and submit for approval
3. Discuss alternatives like sharding or data archival"

**Output** (if user chooses option 1):
```json
{
  "intent": "create_database",
  "confidence": 0.95,
  "parameters": {
    "name": "database-name",
    "type": "mongodb",
    "size": "100gb",
    "environment": "production"
  },
  "governance": {
    "status": "compliant",
    "warnings": [],
    "approvals_required": []
  }
}
```

## 6. Integration with Other Components

### 6.1 Input Sources

The component accepts input from:
- Natural Language Interface (direct user input)
- Conversation History (for context)
- User Profile (for defaults and preferences)

### 6.2 Output Destinations

The component sends its structured output to:
- MCP-Based Tool System (primary consumer)
- Audit & Traceability System (for logging)
- Conversation Manager (for maintaining context)

### 6.3 Error Handling

The component implements robust error handling:
- **Low Confidence Intents**: Trigger clarification questions
- **Missing Required Parameters**: Request additional information
- **Invalid Parameter Values**: Provide feedback and request correction
- **Unsupported Intents**: Inform the user and suggest alternatives

## 7. Technical Implementation

### 7.1 Technology Stack

- **Language Model**: Fine-tuned version of a capable LLM (e.g., GPT-4, Claude)
- **Entity Recognition**: Custom NER (Named Entity Recognition) model
- **Schema Management**: JSOn Schema for parameter definitions
- **Validation**: Custom validation engine with rule-based checks

### 7.2 Performance Considerations

- **Caching**: Cache common intent classifications to improve response time
- **Batch Processing(*: Process multiple messages in a conversation together for better context
- **Confidence Thresholds**: Adjust thresholds based on criticality of the operation
- **Fallback Mechanisms**: Simple rule-based processing when models are unavailable

### 7.3 Monitoring and Improvement

- **Accuracy Tracking**: Monitor intent recognition and parameter extraction accuracy
- **User Feedback**: Collect feedback on incorrect interpretations
- **Continuous Training**: Regularly update models with new examples
- **A/B Testing(*: Test different approaches to improve performance

### 7.4 Policy Integration Architecture
The component integrates with the governance system through:

- **Policy Cache**: In-memory cache of frequently accessed governance policies
- **Policy Retrieval Service**: API-based service for retrieving relevant policies based on context
- **Policy Translation Module**: Converts governance policies into LLM prompts and validation rules
- **Feedback Engine**: Generates user-friendly explanations of governance constraints

## 8. Governance and Security

### 8.1 Input Validation

- **Sanitization**: Remove potentially malicious input
- **Length Limits**: Restrict input size to prevent resource exhaustion
- **Rate Limiting(*: Prevent abuse through request throttling

### 8.2 Parameter Validation

- **Type Checking**: Verify parameter types match expected values
- **Range Checking**: Ensure numeric values are within acceptable ranges
- **Enumeration Validation**: Confirm enum values are from the allowed set
- **Pattern Matching**: Validate string formats (e.g., naming conventions)

### 8.3 Access Control

- **User Permissions**: Validate that the user has permission to request the intent
- **Resource Quotas**: Check against user/team resource quotas
- **Approval Workflows**: Route high-impact requests for approval

## 9. Conclusion

The Intent Recognition & Parameter Extraction component serves as the critical bridge between natural language developer requests and the structured processing required by the rest of the system. By accurately identifying what developers want to create and extracting the specific configuration parameters, this component enables the entire AI-powered IDP to function effectively.

Through a combination of advanced language models, structured schemas, and robust validation, this component ensures that developer intent is captured accurately and completely, setting the stage for successful infrastructure provisioning through the MCP-based tool system.

This component represents the first step in transforming natural language into governed infrastructure, embodying our principle of making infrastructure more accessible while maintaining the governance and consistency principles of modern infrastructure management.
